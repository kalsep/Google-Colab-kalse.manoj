{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled9.ipynb","provenance":[],"authorship_tag":"ABX9TyMluLq4BcC08j3YQIBhY85w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NMpn9wQcCGke","executionInfo":{"status":"ok","timestamp":1646281871546,"user_tz":-330,"elapsed":3179,"user":{"displayName":"pravin Kalse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKZIEc7LtJXLIIKJvXfUw2IhFNU7qmRwYZrLxydA=s64","userId":"11906050196587244661"}},"outputId":"1b4f1118-e778-4251-976f-3de9d379d4e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"]}],"source":["from __future__ import print_function\n","import numpy as np\n","import tflearn\n","import pandas as pd\n","from tflearn.data_utils import to_categorical, pad_sequences, VocabularyProcessor"]},{"cell_type":"code","source":["with open('/polarity.txt') as f:\n","    content = f.readlines()\n","#print(content)\n","\n","with open('/classlabel.txt') as f:\n","    content1 = f.readlines()\n","#print(content1)"],"metadata":{"id":"yDp8ejfcC40r","executionInfo":{"status":"ok","timestamp":1646281925404,"user_tz":-330,"elapsed":27,"user":{"displayName":"pravin Kalse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKZIEc7LtJXLIIKJvXfUw2IhFNU7qmRwYZrLxydA=s64","userId":"11906050196587244661"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["tweets = content\n","max_tweet_length = 120\n","min_frequency = 2 \n","vp = tflearn.data_utils.VocabularyProcessor(max_tweet_length, min_frequency=min_frequency)\n","vp = vp.fit(tweets)\n","val = len(vp.vocabulary_)\n","print(val)\n","tweets_parsed = vp.transform(tweets)\n","vp.save('my_dictionary')\n","print(vp)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":518},"id":"A_I27K6FDJlV","executionInfo":{"status":"error","timestamp":1646281954828,"user_tz":-330,"elapsed":63,"user":{"displayName":"pravin Kalse","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKZIEc7LtJXLIIKJvXfUw2IhFNU7qmRwYZrLxydA=s64","userId":"11906050196587244661"}},"outputId":"27cd55b5-765e-4b96-b2e6-b84e9c4e808e"},"execution_count":5,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-3410fa151cc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmax_tweet_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmin_frequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVocabularyProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_tweet_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_frequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mvp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tflearn/data_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, max_document_length, min_frequency, vocabulary, tokenizer_fn)\u001b[0m\n\u001b[1;32m    203\u001b[0m                  \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                  tokenizer_fn=None):\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mVocabularyProcessor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_VocabularyProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         self.__dict__['_vocabulary_processor'] = _VocabularyProcessor(\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":[""],"metadata":{"id":"pN78uKdPDQxj"},"execution_count":null,"outputs":[]}]}